English | [ç®€ä½“ä¸­æ–‡](README.md)

# go-datax

Go version of DataX data synchronization tool, 100% compatible with DataX JSON configuration format.

## âœ¨ Key Features

- ğŸš€ **High Performance**: Go implementation with high-concurrency data transfer
- ğŸ”§ **Zero Dependencies**: Single binary file, no additional installation required
- ğŸ“Š **30+ Data Sources**: Support for mainstream databases and storage systems
- âœ… **100% Compatible**: Full compatibility with DataX Java configuration files
- âš¡ **Go Optimizations**: Enhanced splitPk support and JSON file processing

## ğŸ†• Go Version Enhancements

### Non-Numeric splitPk Support
Unlike the Java version which only supports numeric splitPk, the Go version supports:
- **Numeric Types**: `int`, `bigint`, `decimal`, etc. (compatible with Java version)
- **String Types**: `varchar`, `text`, and other string field partitioning
- **Date Types**: `date`, `timestamp`, and other time field partitioning

```json
{
  "reader": {
    "parameter": {
      "splitPk": "create_time",  // Support for date-time field partitioning
      "where": "status = 'active'"
    }
  }
}
```

### JSON File Data Source Support
New dedicated JSON file reader and writer plugins:
- **JsonFileReader**: Read JSON/JSONL files
- **JsonFileWriter**: Write JSON format files
- **Auto Format Detection**: Automatically detects standard JSON vs JSONL format

```json
{
  "reader": {
    "name": "jsonfilereader",
    "parameter": {
      "path": ["/data/input.json"],
      "encoding": "UTF-8"
    }
  }
}
```

## ğŸ—ï¸ Architecture Design

Adopts DataX three-layer architecture design:

```
Engine Layer
â”œâ”€â”€ JobContainer
â””â”€â”€ TaskGroupContainer
    â”œâ”€â”€ Reader Task
    â”œâ”€â”€ Channel
    â””â”€â”€ Writer Task
```

## ğŸ“¦ Supported Data Sources

DataX has a comprehensive plugin ecosystem with mainstream RDBMS databases, NoSQL, and big data computing systems already integrated.

| Type | Data Source | Reader | Writer | Documentation |
|------|-------------|:------:|:------:|---------------|
| **Relational Databases** | MySQL | âœ… | âœ… | [Reader](docs/plugins/mysqlreader.md) Â· [Writer](docs/plugins/mysqlwriter.md) |
| | PostgreSQL | âœ… | âœ… | [Reader](docs/plugins/postgresqlreader.md) Â· [Writer](docs/plugins/postgresqlwriter.md) |
| | Oracle | âœ… | âœ… | [Reader](docs/plugins/oraclereader.md) Â· [Writer](docs/plugins/oraclewriter.md) |
| | SQL Server | âœ… | âœ… | [Reader](docs/plugins/sqlserverreader.md) Â· [Writer](docs/plugins/sqlserverwriter.md) |
| | SQLite | âœ… | âœ… | [Reader](docs/plugins/sqlitereader.md) Â· [Writer](docs/plugins/sqlitewriter.md) |
| | OceanBase | âœ… | âœ… | [Reader](docs/plugins/oceanbasereader.md) Â· [Writer](docs/plugins/oceanbasewriter.md) |
| | GaussDB | âœ… | âœ… | [Reader](docs/plugins/gaussdbreader.md) Â· [Writer](docs/plugins/gaussdbwriter.md) |
| | Sybase ASE | âœ… | âœ… | [Reader](docs/plugins/sybasereader.md) Â· [Writer](docs/plugins/sybasewriter.md) |
| **Big Data Storage** | ClickHouse | âœ… | âœ… | [Reader](docs/plugins/clickhousereader.md) Â· [Writer](docs/plugins/clickhousewriter.md) |
| | StarRocks | âœ… | âœ… | [Reader](docs/plugins/starrocksreader.md) Â· [Writer](docs/plugins/starrockswriter.md) |
| | Apache Doris | âœ… | âœ… | [Reader](docs/plugins/dorisreader.md) Â· [Writer](docs/plugins/doriswriter.md) |
| | HDFS | âœ… | âœ… | [Reader](docs/plugins/hdfsreader.md) Â· [Writer](docs/plugins/hdfswriter.md) |
| | Databend | âŒ | âœ… | [Writer](docs/plugins/databendwriter.md) |
| **NoSQL Databases** | MongoDB | âœ… | âœ… | [Reader](docs/plugins/mongoreader.md) Â· [Writer](docs/plugins/mongowriter.md) |
| | Cassandra | âœ… | âœ… | [Reader](docs/plugins/cassandrareader.md) Â· [Writer](docs/plugins/cassandrawriter.md) |
| | Neo4j | âŒ | âœ… | [Writer](docs/plugins/neo4jwriter.md) |
| | ElasticSearch | âŒ | âœ… | [Writer](docs/plugins/elasticsearchwriter.md) |
| **Time Series Databases** | TDengine | âœ… | âœ… | [Reader](docs/plugins/tdenginereader.md) Â· [Writer](docs/plugins/tdenginewriter.md) |
| **File Storage** | TXT Files | âœ… | âœ… | [Reader](docs/plugins/txtfilereader.md) Â· [Writer](docs/plugins/txtfilewriter.md) |
| | JSON Files | âœ… | âœ… | [Reader](docs/plugins/jsonfilereader.md) Â· [Writer](docs/plugins/jsonfilewriter.md) |
| | FTP/SFTP | âœ… | âœ… | [Reader](docs/plugins/ftpreader.md) Â· [Writer](docs/plugins/ftpwriter.md) |
| **Cloud Storage** | OSS | âœ… | âŒ | [Reader](docs/plugins/ossreader.md) |
| **Stream Data** | Stream | âœ… | âœ… | [Reader](docs/plugins/streamreader.md) Â· [Writer](docs/plugins/streamwriter.md) |

## ğŸš€ Quick Start

### Installation

#### Option 1: Download Prebuilt Binary
```bash
# Linux x86_64
wget https://github.com/longkeyy/go-datax/releases/latest/download/datax-linux-amd64
chmod +x datax-linux-amd64
sudo mv datax-linux-amd64 /usr/local/bin/datax

# macOS Apple Silicon
wget https://github.com/longkeyy/go-datax/releases/latest/download/datax-darwin-arm64
chmod +x datax-darwin-arm64
sudo mv datax-darwin-arm64 /usr/local/bin/datax
```

#### Option 2: Docker Image
```bash
docker pull ghcr.io/longkeyy/go-datax:latest
```

#### Option 3: Build from Source
```bash
git clone https://github.com/longkeyy/go-datax.git
cd go-datax
make build
```

### Basic Usage

1. **Create Configuration File** (`config.json`):
```json
{
  "job": {
    "setting": {
      "speed": {
        "channel": 3
      }
    },
    "content": [{
      "reader": {
        "name": "postgresqlreader",
        "parameter": {
          "username": "postgres",
          "password": "password",
          "connection": [{
            "jdbcUrl": ["jdbc:postgresql://localhost:5432/source_db"],
            "table": ["user_table"]
          }],
          "column": ["id", "name", "email"],
          "splitPk": "id"
        }
      },
      "writer": {
        "name": "mysqlwriter",
        "parameter": {
          "username": "root",
          "password": "password",
          "connection": [{
            "jdbcUrl": "jdbc:mysql://localhost:3306/target_db",
            "table": ["user_table"]
          }],
          "column": ["id", "name", "email"]
        }
      }
    }]
  }
}
```

2. **Execute Data Synchronization**:
```bash
# Run locally
./datax -job config.json

# Run with Docker
docker run --rm -v $(pwd)/config.json:/config.json ghcr.io/longkeyy/go-datax:latest -job /config.json
```

### Configuration Parameters

#### Performance Control
```json
{
  "job": {
    "setting": {
      "speed": {
        "channel": 4,        // Concurrent channels
        "record": 10000,     // Record limit
        "byte": 1048576      // Byte limit
      },
      "errorLimit": {
        "record": 100,       // Error record threshold
        "percentage": 0.05   // Error rate threshold
      }
    }
  }
}
```

#### Data Filtering and Partitioning
```json
{
  "reader": {
    "parameter": {
      "where": "create_time > '2023-01-01'",
      "splitPk": "user_id",          // Supports numeric, string, and date types
      "fetchSize": 1024
    }
  }
}
```

## ğŸ“‹ Feature Comparison (vs DataX Java)

### Core Features
- âœ… **Three-Layer Architecture**: Engine-JobContainer-TaskGroupContainer
- âœ… **Plugin System**: Reader/Writer factory pattern registration
- âœ… **Data Model**: Record/Column type system
- âœ… **Configuration Management**: 100% JSON configuration compatibility
- âœ… **Monitoring & Statistics**: Real-time transfer monitoring and performance metrics
- âœ… **Error Control**: errorLimit and fault tolerance mechanisms

### Data Synchronization
- âœ… **Full Sync**: Complete table data synchronization
- âœ… **Incremental Sync**: Business-based incremental sync via WHERE conditions
- âœ… **Heterogeneous Sync**: Cross data source type synchronization
- âœ… **Partitioned Concurrency**: splitPk-based parallel processing
- âŒ **Real-time Sync**: Not supported (consistent with Java version)

### Data Transformation
- âœ… **dx_filter**: Data filtering
- âœ… **dx_substr**: String truncation
- âœ… **dx_replace**: String replacement
- âœ… **dx_pad**: String padding
- âœ… **dx_digest**: Data digest
- âŒ **dx_groovy**: Script transformation (planned)

### Go Version Enhancements
- ğŸš€ **Non-Numeric splitPk**: Support for string and date type partitioning
- ğŸš€ **JSON File Support**: JsonFileReader/Writer
- ğŸš€ **Pure Go Drivers**: Oracle/Sybase without client requirements
- ğŸš€ **Single Binary**: Zero-dependency deployment

### Data Source Support
- âœ… **Relational Databases** (8): MySQL, PostgreSQL, Oracle, SQL Server, SQLite, OceanBase, GaussDB, Sybase
- âœ… **Big Data Storage** (6): HDFS, ClickHouse, StarRocks, Doris, Databend, TDengine
- âœ… **NoSQL Databases** (4): MongoDB, Cassandra, Neo4j, ElasticSearch
- âœ… **File Storage** (3): TXT Files, JSON Files, FTP/SFTP
- âœ… **Cloud Storage** (1): OSS
- âœ… **Stream Data** (1): Stream
- âŒ **Planned Support**: HBase, MaxCompute, OTS

**Total**: 21 data sources, 42 Reader/Writer plugins

## ğŸ“– Documentation

### User Documentation
- [Quick Start](docs/QUICKSTART.md) - Installation and basic usage guide
- [User Manual](docs/USER_GUIDE.md) - Data synchronization scenarios and configuration details
- [Data Transformation](docs/TRANSFORMER.md) - Built-in Transformer functionality

### Developer Documentation
- [System Architecture](docs/ARCHITECTURE.md) - Go language implementation architecture design
- [Plugin Development](docs/PLUGIN_DEVELOPMENT.md) - Extension plugin development guide
- [Plugin Documentation](docs/plugins/) - Detailed configuration for each plugin

## ğŸ¤ Contributing

Contributions are welcome! Please submit Issues and Pull Requests to help improve the project.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ”— Related Projects

- [DataX (Java)](https://github.com/alibaba/DataX) - Alibaba's open-source heterogeneous data source offline synchronization tool
